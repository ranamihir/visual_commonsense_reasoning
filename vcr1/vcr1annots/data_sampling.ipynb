{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['train', 'val', 'test']\n",
    "answer_types = ['answer', 'rationale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'sample' | 'mini'\n",
    "size_type = 'sample'\n",
    "if size_type == 'sample':\n",
    "    data_sizes = [50000, 10000, 10000]\n",
    "elif size_type == 'mini':\n",
    "    data_sizes = [5000, 1000, 1000]\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace model dataset with the newly created one\n",
    "replace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_samples(data_type, data_size, size_type, replace=False):\n",
    "    with open('{}-orig.jsonl'.format(data_type), 'r') as f_in:\n",
    "        data = [json.loads(s) for s in f_in]\n",
    "    keep_ind = np.random.choice(range(len(data)), size=data_size)\n",
    "    data_sample = [data[i] for i in keep_ind]\n",
    "    \n",
    "    with open('{}-{}.jsonl'.format(data_type, size_type), 'w') as f_out:\n",
    "        for line in data_sample:\n",
    "            f_out.write(json.dumps(line)+'\\n')\n",
    "    \n",
    "    if replace:\n",
    "        data_folder = '../../data/'\n",
    "        source = '{}-{}.jsonl'.format(data_type, size_type)\n",
    "        dest = '{}.jsonl'.format(data_type)\n",
    "        subprocess.call('cp {} {}'.format(source, dest), shell=True)\n",
    "        subprocess.call('rm {} {}'.format(source, dest), cwd=data_folder, shell=True)\n",
    "        subprocess.call('ln -s ../vcr1/vcr1annots/{} {}'.format(source, source), cwd=data_folder, shell=True)\n",
    "        subprocess.call('ln -s ../vcr1/vcr1annots/{} {}'.format(dest, dest), cwd=data_folder, shell=True)\n",
    "    \n",
    "    return keep_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "indices = {}\n",
    "for data_type, data_size in zip(data_types, data_sizes):\n",
    "    print(data_type)\n",
    "    indices[data_type] = create_data_samples(data_type, data_size, size_type, replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_samples(answer_type, data_type, size_type, replace=False):\n",
    "    group_items = []\n",
    "    data_folder = '../../data/'\n",
    "    with h5py.File('{}bert_da_{}_{}_orig.h5'.format(data_folder, answer_type, data_type), 'r') as f:\n",
    "        for ind in indices[data_type]:\n",
    "            group_items.append({k: np.array(v, dtype=np.float16) for k, v in f[str(ind)].items()})\n",
    "\n",
    "    with h5py.File('{}bert_da_{}_{}_{}.h5'.format(data_folder, answer_type, data_type, size_type), 'w') as f:\n",
    "        for ind in range(len(group_items)):\n",
    "            group = f.create_group(str(ind))\n",
    "            for k, v in group_items[ind].items():\n",
    "                group.create_dataset(k, data=v)\n",
    "    \n",
    "    if replace:\n",
    "        source = 'bert_da_{}_{}_{}.h5'.format(answer_type, data_type, size_type)\n",
    "        dest = 'bert_da_{}_{}.h5'.format(answer_type, data_type)\n",
    "        subprocess.call('cp {} {}'.format(source, dest), cwd=data_folder, shell=True)\n",
    "        subprocess.call('cd ../vcr1/vcr1annots', cwd=data_folder, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "\ttrain\n",
      "\tval\n",
      "\ttest\n",
      "\n",
      "rationale\n",
      "\ttrain\n",
      "\tval\n",
      "\ttest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for answer_type in answer_types:\n",
    "    print(answer_type)\n",
    "    for data_type in data_types:\n",
    "        print('\\t'+data_type)\n",
    "        create_embedding_samples(answer_type, data_type, size_type, replace)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
